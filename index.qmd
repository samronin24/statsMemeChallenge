---
title: "Selection Bias & Missing Data Challenge - Part 2"
subtitle: "Creating a Statistics Meme: Visualizing Selection Bias"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Visualizing Selection Bias: A Statistics Meme

Selection bias occurs when observed data isn't representative of the population. This visualization demonstrates how systematic missing data patterns can distort our understanding of reality.

## The Four-Panel Meme

The meme below shows four stages of data collection and analysis:

```{python}
#| label: stippling-functions
#| echo: false
#| eval: true
#| message: false
#| warning: false

import numpy as np

def compute_importance(
    gray_img: np.ndarray,
    extreme_downweight: float = 0.5,
    extreme_threshold_low: float = 0.4,
    extreme_threshold_high: float = 0.8,
    extreme_sigma: float = 0.1,
    mid_tone_boost: float = 0.4,
    mid_tone_sigma: float = 0.2,
):
    """
    Importance map computation that downweights extreme tones (very dark and very light)
    using smooth functions, while boosting mid-tones.
    """
    I = np.clip(gray_img, 0.0, 1.0)
    
    # Invert brightness: dark areas should get more dots (higher importance)
    I_inverted = 1.0 - I
    
    # Create smooth downweighting mask for extreme tones
    dark_mask = np.exp(-((I - 0.0) ** 2) / (2.0 * (extreme_sigma ** 2)))
    dark_mask = np.where(I < extreme_threshold_low, dark_mask, 0.0)
    if dark_mask.max() > 0:
        dark_mask = dark_mask / dark_mask.max()
    
    light_mask = np.exp(-((I - 1.0) ** 2) / (2.0 * (extreme_sigma ** 2)))
    light_mask = np.where(I > extreme_threshold_high, light_mask, 0.0)
    if light_mask.max() > 0:
        light_mask = light_mask / light_mask.max()
    
    extreme_mask = np.maximum(dark_mask, light_mask)
    importance = I_inverted * (1.0 - extreme_downweight * extreme_mask)
    
    # Add smooth gradual mid-tone boost
    mid_tone_center = 0.65
    mid_tone_gaussian = np.exp(-((I - mid_tone_center) ** 2) / (2.0 * (mid_tone_sigma ** 2)))
    if mid_tone_gaussian.max() > 0:
        mid_tone_gaussian = mid_tone_gaussian / mid_tone_gaussian.max()
    
    importance = importance * (1.0 + mid_tone_boost * mid_tone_gaussian)
    
    # Normalize to [0,1]
    m, M = importance.min(), importance.max()
    if M > m: 
        importance = (importance - m) / (M - m)
    return importance


def toroidal_gaussian_kernel(h: int, w: int, sigma: float):
    """Create a periodic (toroidal) 2D Gaussian kernel centered at (0,0)."""
    y = np.arange(h)
    x = np.arange(w)
    dy = np.minimum(y, h - y)[:, None]
    dx = np.minimum(x, w - x)[None, :]
    kern = np.exp(-(dx**2 + dy**2) / (2.0 * sigma**2))
    s = kern.sum()
    if s > 0:
        kern /= s
    return kern


def void_and_cluster(
    input_img: np.ndarray,
    percentage: float = 0.08,
    sigma: float = 0.9,
    content_bias: float = 0.9,
    importance_img: np.ndarray | None = None,
    noise_scale_factor: float = 0.1,
):
    """Generate blue noise stippling pattern from input image using a modified void-and-cluster algorithm."""
    I = np.clip(input_img, 0.0, 1.0)
    h, w = I.shape

    if importance_img is None:
        importance = compute_importance(I)
    else:
        importance = np.clip(importance_img, 0.0, 1.0)

    kernel = toroidal_gaussian_kernel(h, w, sigma)
    energy_current = -importance * content_bias
    final_stipple = np.ones_like(I)
    samples = []

    def energy_splat(y, x):
        return np.roll(np.roll(kernel, shift=y, axis=0), shift=x, axis=1)

    num_points = int(I.size * percentage)

    # Choose first point near center
    cy, cx = h // 2, w // 2
    r = min(20, h // 10, w // 10)
    ys = slice(max(0, cy - r), min(h, cy + r))
    xs = slice(max(0, cx - r), min(w, cx + r))
    region = energy_current[ys, xs]
    flat = np.argmin(region)
    y0 = flat // (region.shape[1]) + (cy - r)
    x0 = flat % (region.shape[1]) + (cx - r)

    energy_current = energy_current + energy_splat(y0, x0)
    energy_current[y0, x0] = np.inf
    samples.append((y0, x0, I[y0, x0]))
    final_stipple[y0, x0] = 0.0

    # Iteratively place remaining points
    for i in range(1, num_points):
        # Show progress every 5% or every 500 points, whichever is more frequent
        if i % max(1, min(num_points // 20, 500)) == 0:
            progress = (i / num_points) * 100
            print(f"  Progress: {progress:.0f}% ({i}/{num_points} points)", flush=True)
        
        exploration = 1.0 - (i / num_points) * 0.5
        noise = np.random.normal(0.0, noise_scale_factor * content_bias * exploration, size=energy_current.shape)
        energy_with_noise = energy_current + noise

        pos_flat = np.argmin(energy_with_noise)
        y = pos_flat // w
        x = pos_flat % w

        energy_current = energy_current + energy_splat(y, x)
        energy_current[y, x] = np.inf

        samples.append((y, x, I[y, x]))
        final_stipple[y, x] = 0.0

    return final_stipple, np.array(samples)
```

Now let's generate the stippled image:

```{python}
#| label: generate-stipple
#| echo: false
#| eval: true
#| message: true
#| warning: false

import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import sys

# Load original image
print("Loading image...", flush=True)
original_img = Image.open('sam_headshot.jpg')
if original_img.mode != 'L':
    original_img = original_img.convert('L')
original_array = np.array(original_img, dtype=np.float32) / 255.0
print(f"Image loaded: {original_array.shape}", flush=True)

# Resize image if needed (matching Part 1 approach)
# Using smaller max_size for faster processing during rendering
max_size = 400
if original_array.shape[0] > max_size or original_array.shape[1] > max_size:
    scale = max_size / max(original_array.shape[0], original_array.shape[1])
    new_size = (int(original_array.shape[1] * scale), int(original_array.shape[0] * scale))
    img_resized_pil = original_img.resize(new_size, Image.Resampling.LANCZOS)
    if img_resized_pil.mode != 'L':
        img_resized_pil = img_resized_pil.convert('L')
    img_resized = np.array(img_resized_pil, dtype=np.float32) / 255.0
    print(f"Resized image from {original_array.shape} to {img_resized.shape} for processing", flush=True)
else:
    img_resized = original_array.copy()

# Ensure img_resized is 2D grayscale
if len(img_resized.shape) > 2:
    img_resized = img_resized[:, :, 0]
elif len(img_resized.shape) == 2:
    pass
else:
    raise ValueError(f"Unexpected image shape: {img_resized.shape}")

# Compute importance map using the function from Part 1
print("Computing importance map...", flush=True)
importance_map = compute_importance(
    img_resized,
    extreme_downweight=0.5,
    extreme_threshold_low=0.2,
    extreme_threshold_high=0.8,
    extreme_sigma=0.1
)
print("Importance map computed.", flush=True)

# Generate stippling pattern
# Using slightly lower percentage for faster rendering while maintaining quality
percentage = 0.06
num_points = int(img_resized.size * percentage)
print(f"Generating blue noise stippling pattern ({num_points} points)...", flush=True)
print("This may take 1-2 minutes. Please be patient...", flush=True)
stipple_pattern, samples = void_and_cluster(
    img_resized,
    percentage=percentage,
    sigma=0.9,
    content_bias=0.9,
    importance_img=importance_map,
    noise_scale_factor=0.1,
)

print(f"✓ Generated {len(samples)} stipple points", flush=True)
print(f"Stipple pattern shape: {stipple_pattern.shape}", flush=True)

# Store as stipple_array for use in meme generation
stipple_array = stipple_pattern.copy()

# If the stippled image was resized, resize it back to match original dimensions
height, width = original_array.shape
if stipple_array.shape != original_array.shape:
    stipple_array = np.array(Image.fromarray((stipple_array * 255).astype(np.uint8)).resize((width, height), Image.Resampling.LANCZOS)) / 255.0
```

### Step 2: Create the Four-Panel Meme

Now let's create the meme using your stippled image:

```{python}
#| label: create-meme
#| echo: false
#| eval: true
#| fig-width: 12
#| fig-height: 3

import numpy as np
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt

# Get image dimensions from the stippled array (generated in previous step)
height, width = stipple_array.shape

# Step 2: Create the block letter "S"
# Create a white background image
s_img = Image.new('L', (width, height), color=255)
draw = ImageDraw.Draw(s_img)

# Try to use a bold font, fallback to default if not available
try:
    # Try to find a bold font (adjust path as needed for your system)
    font_size = int(height * 0.85)  # 85% of image height
    try:
        font = ImageFont.truetype("/System/Library/Fonts/Supplemental/Arial Bold.ttf", font_size)
    except:
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
        except:
            font = ImageFont.load_default()
except:
    font = ImageFont.load_default()

# Get text bounding box to center it
text = "S"
bbox = draw.textbbox((0, 0), text, font=font)
text_width = bbox[2] - bbox[0]
text_height = bbox[3] - bbox[1]

# Center the text
x = (width - text_width) // 2
y = (height - text_height) // 2

# Draw the "S" in black
draw.text((x, y), text, fill=0, font=font)

# Convert to numpy array (0.0 = black, 1.0 = white)
s_array = np.array(s_img, dtype=np.float32) / 255.0

# Step 3: Create the masked estimate
# Create binary mask: where "S" is black (pixels < 0.5), that's where data is missing
threshold = 0.5
mask = s_array < threshold

# Apply mask: where "S" is black, remove stipples (set to white)
masked_estimate = np.where(mask, 1.0, stipple_array)

# Step 4: Assemble the four-panel meme
fig, axes = plt.subplots(1, 4, figsize=(12, 3))
fig.patch.set_facecolor('#FFE5E5')  # Light pink background

panels = [
    (original_array, "Reality"),
    (stipple_array, "Your Model"),
    (s_array, "Selection Bias"),
    (masked_estimate, "Estimate")
]

for ax, (data, label) in zip(axes, panels):
    ax.imshow(data, cmap='gray', vmin=0, vmax=1)
    ax.set_title(label, fontsize=14, fontweight='bold', pad=10)
    ax.axis('off')

plt.tight_layout()
plt.subplots_adjust(wspace=0, hspace=0)
plt.savefig('statistics_meme.png', dpi=200, bbox_inches='tight', facecolor='#FFE5E5')
plt.show()
```

## Understanding Selection Bias

**Selection bias** occurs when the data we observe differs from the population we want to study, leading to incorrect conclusions. This challenge demonstrates selection bias through a visual metaphor: just as the "S" pattern systematically removes stipples from certain regions of the image, selection bias systematically excludes certain groups or observations from our data. The importance of understanding selection bias cannot be overstated—it affects everything from medical research and public policy to business decisions and social science studies. When we fail to recognize selection bias, we risk making decisions based on incomplete or misleading information, potentially perpetuating inequalities or missing critical insights about the true nature of the phenomena we're studying.

This visualization demonstrates how **selection bias** can distort our understanding of reality:

- **Reality** shows the true, complete picture—your original image represents the full population.
- **Your Model** represents your data collection method—the stippled version shows what you actually observe (like survey responses or experimental data).
- **Selection Bias** shows the systematic pattern of missing data—the bold "S" represents where data is systematically excluded or unavailable.
- **Estimate** reveals the biased result—when you only see data outside the "S" region, your estimate of reality becomes distorted.

This meme illustrates a fundamental question in statistics: **"Does my sample match my population of interest?"** When selection bias occurs (represented by the "S"), the answer is no—your sample systematically excludes certain parts of the population, leading to biased estimates.
